{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modified_mnist_Xception.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9biibEqym5mT","colab_type":"text"},"source":["# Setup\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"D5CfDVCbZVl_","colab_type":"code","outputId":"7987df7f-fac5-4745-9a62-4b57d0abef66","executionInfo":{"status":"ok","timestamp":1573405838774,"user_tz":300,"elapsed":45037,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["# Mounting Google Drive locally\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tge1CP-OyuTd","colab_type":"code","colab":{}},"source":["# Navigate to folder containing project\n","import os\n","os.chdir(\"drive/My Drive/COMP 551/Projects/Project3\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQBbqqtNyDvq","colab_type":"code","colab":{}},"source":["from google.colab.patches import cv2_imshow\n","# Function to show a single image \n","def show_single_picture(img):\n","    \"\"\" Plot an image \"\"\"\n","    cv2_imshow(img*255)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rv-OjnpHyHgg","colab_type":"text"},"source":["# Xception\n"]},{"cell_type":"code","metadata":{"id":"OFDEoZXFY8TZ","colab_type":"code","outputId":"dc29a716-c2da-452f-da4b-2e4658a60f20","executionInfo":{"status":"ok","timestamp":1573405841848,"user_tz":300,"elapsed":48088,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle \n","import datetime\n","from sklearn.model_selection import train_test_split\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","\n","# Using pre-trained models\n","from keras.applications import VGG16, VGG19, InceptionResNetV2, Xception, NASNetLarge\n","from keras import datasets, optimizers\n","from keras.layers import Conv2D, Dropout, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PxrG5_k64cZI","colab_type":"code","outputId":"30c1712b-180e-4042-f25d-67c8b8582b0e","executionInfo":{"status":"ok","timestamp":1573405870096,"user_tz":300,"elapsed":73475,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Read data \n","x_train = pd.read_pickle(\"data/x_train.pkl\")\n","x_valid = pd.read_pickle(\"data/x_valid.pkl\")\n","y_train = pd.read_pickle(\"data/y_train.pkl\")\n","y_valid = pd.read_pickle(\"data/y_valid.pkl\")\n","\n","# Convert training/valid images from grayscale to rgb (3 channels)\n","x_train = np.stack((x_train,x_train,x_train), axis=-1)\n","x_valid = np.stack((x_valid,x_valid,x_valid), axis=-1)\n","\n","# Image dimensions \n","image_size = x_train[0].shape[0]\n","num_channels = x_train[0].shape[2]\n","print(\"Image size: {0}\\nNumber of channels: {1}\".format(image_size, num_channels))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Image size: 128\n","Number of channels: 3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6tpQI1Kor5XS","colab_type":"text"},"source":["**The goal when applying data augmentation is to increase the generalizability of the model.**\n","Given that our network is constantly seeing new, slightly modified versions of the input data, the network is able to learn more robust features.\n","\n","Reasons to use a data generator\n","- Real-world datasets are often too large to fit into memory.\n","- They also tend to be challenging, requiring us to perform data augmentation to avoid overfitting and increase the ability of our model to generalize.\n","\n","Here's how the ImageDataGenerator works:\n","1. Accepting a batch of images used for training.\n","2. Taking this batch and applying a series of random transformations to each image in the batch (including random rotation, resizing, shearing, etc.).\n","3. Replacing the **original** batch with the **new, randomly transformed batch**.\n","4. Training the CNN on this randomly transformed batch (i.e., the original data itself is not used for training).\n","\n","Keras' ImageDataGenerator executes in-place data augmentation. \n","It is called \"in-place\" and \"on-the-fly\", because data augmentation is done at training time. \n","If we included the original training data along with the augmented data in each batch, then the network would “see” the original training data multiple times, effectively defeating the purpose.\n","The entire point of the data augmentation technique described in this section is to ensure that the network sees “new” images that it has never \"seen\" before at each and every epoch.\n","To accomplish this goal we “replace” the training data with randomly transformed, augmented data.\n","Performing data augmentation is a form of regularization, enabling our model to generalize better. \n","\n","NOTE: we don't apply data augmentation to validation/test data, therefore we don't need a generator.\n","\n","https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n","\n","https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n","\n","https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/"]},{"cell_type":"code","metadata":{"id":"1m5PW__1n7cO","colab_type":"code","colab":{}},"source":["# Construct the training image generator to perform data augmentation (NOTE: since we are working numbers, it is important to set the rotation and the horizontal_flip to 0 and False respectively).\n","datagen = ImageDataGenerator(rotation_range=0, zoom_range=0.10,\n","\twidth_shift_range=0.05, height_shift_range=0.05, shear_range=0,\n","\thorizontal_flip=False,vertical_flip=False, fill_mode=\"nearest\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXXLxwsnwHWZ","colab_type":"code","colab":{}},"source":["# Fit data generator on training data for ZCA whitening\n","datagen.fit(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6JVEbk2G9BE","colab_type":"code","colab":{}},"source":["# Verify image generated by ImageDataGenerator\n","for i in  datagen.flow(x=x_train,y=y_train)[0][0]:\n","  show_single_picture(i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f24zSLUeNjVo","colab_type":"code","colab":{}},"source":["# Initialize number of epochs, batch_size and validation split \n","WARMUP = 10\n","EPOCHS = 30\n","batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6idnJIa6Pip","colab_type":"code","colab":{}},"source":["# Initialize optimizer\n","learning_rate = 5e-4\n","optimizer = optimizers.SGD(lr=learning_rate, momentum=0.9) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T93eIA_VlgBy","colab_type":"text"},"source":["**Fine Tune Pre-Trained Models**"]},{"cell_type":"code","metadata":{"id":"T28FC9lQtcwd","colab_type":"code","outputId":"fede6344-4506-4b52-bf22-2139d7530516","executionInfo":{"status":"ok","timestamp":1573368836985,"user_tz":300,"elapsed":980189,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Create a model using pretrained Xception\n","base_model = Xception(weights='imagenet', include_top=False, input_tensor=Input(shape=(image_size, image_size, num_channels))) # assumes data_format = \"channels_last\"\n","\n","# Add a global spatial average pooling layer\n","top_network = base_model.output\n","top_network = Flatten()(top_network)\n","# Add a fully-connected layer    \n","top_network = Dense(128, activation='relu')(top_network)\n","# Add a Dropout layer\n","top_network = Dropout(0.20)(top_network)\n","# Add a fully-connected layer    \n","top_network = Dense(32, activation='relu')(top_network)\n","# Add a logistic layer with 10 classes\n","top_network = Dense(10, activation='softmax')(top_network)\n","\n","# Create model\n","model = Model(inputs=base_model.input, outputs=top_network)\n","\n","# Step 1: Train only the top layers (i.e. fully connected layers) which were randomly initialized. Freeze all Xception layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Display trainable layers\n","for layer in model.layers:\n","  print(\"{}: {}\".format(layer, layer.trainable))\n","\n","# Compile the model (should be done ***after*** setting layers to non-trainable)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","# Print a summary of the model\n","model.summary()\n","\n","# Train the head of the network on new data for a few epochs (all other layers are frozen) -- this will allow the new FC layers to start to become initialized with actual \"learned\" values versus pure random\n","history = model.fit_generator(datagen.flow(x=x_train, y=y_train, batch_size=batch_size), validation_data=(x_valid,y_valid), steps_per_epoch=len(x_train)//batch_size, epochs=WARMUP)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","<keras.engine.input_layer.InputLayer object at 0x7ff8e36d8b00>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff92fbfb630>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8e36d8c88>: False\n","<keras.layers.core.Activation object at 0x7ff8e36d8ef0>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff8e2e5fba8>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d05ebcc0>: False\n","<keras.layers.core.Activation object at 0x7ff8d0600f98>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d05bb5c0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d057de48>: False\n","<keras.layers.core.Activation object at 0x7ff945bf1470>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d0511710>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d04c9a58>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff8e36d69b0>: False\n","<keras.layers.pooling.MaxPooling2D object at 0x7ff8d04d9d68>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d05bb630>: False\n","<keras.layers.merge.Add object at 0x7ff8d04f2e10>: False\n","<keras.layers.core.Activation object at 0x7ff8d049ce10>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d049cc18>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d04605c0>: False\n","<keras.layers.core.Activation object at 0x7ff8d0465ba8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d046ff28>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d042a358>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff94e3855c0>: False\n","<keras.layers.pooling.MaxPooling2D object at 0x7ff8d0433978>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d049c358>: False\n","<keras.layers.merge.Add object at 0x7ff8d03ec208>: False\n","<keras.layers.core.Activation object at 0x7ff8d0402dd8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d0402f28>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d03b9dd8>: False\n","<keras.layers.core.Activation object at 0x7ff8d03c7c50>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d034e8d0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0383b70>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff8d03f2ef0>: False\n","<keras.layers.pooling.MaxPooling2D object at 0x7ff8d0316908>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0402160>: False\n","<keras.layers.merge.Add object at 0x7ff8d032fe48>: False\n","<keras.layers.core.Activation object at 0x7ff8d02d3908>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d02da9e8>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d02dac18>: False\n","<keras.layers.core.Activation object at 0x7ff8d02daeb8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d02e7908>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d02a1c88>: False\n","<keras.layers.core.Activation object at 0x7ff8d02afb38>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d02a97b8>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d026ea58>: False\n","<keras.layers.merge.Add object at 0x7ff8d027de10>: False\n","<keras.layers.core.Activation object at 0x7ff8d02d3e48>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d0210da0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0238f60>: False\n","<keras.layers.core.Activation object at 0x7ff8d01cadd8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d01d1550>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0207898>: False\n","<keras.layers.core.Activation object at 0x7ff8d0196f60>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d019d320>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0156668>: False\n","<keras.layers.merge.Add object at 0x7ff8d015ec88>: False\n","<keras.layers.core.Activation object at 0x7ff8d0217f98>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d0173fd0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d0124f28>: False\n","<keras.layers.core.Activation object at 0x7ff8d012dc50>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d0133fd0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d00f3400>: False\n","<keras.layers.core.Activation object at 0x7ff8d00faa20>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d00fedd8>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d00be1d0>: False\n","<keras.layers.merge.Add object at 0x7ff8d004db38>: False\n","<keras.layers.core.Activation object at 0x7ff8d0115518>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d005cb38>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8d000da90>: False\n","<keras.layers.core.Activation object at 0x7ff8d0084f60>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8d00130f0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8799f9e80>: False\n","<keras.layers.core.Activation object at 0x7ff879a118d0>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8799f4fd0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8799c9c50>: False\n","<keras.layers.merge.Add object at 0x7ff8799d6a58>: False\n","<keras.layers.core.Activation object at 0x7ff8d005c470>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8799eb668>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff87999f5f8>: False\n","<keras.layers.core.Activation object at 0x7ff8799a69b0>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8799ad748>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8799639e8>: False\n","<keras.layers.core.Activation object at 0x7ff8798f5da0>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8798fb518>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8798b4860>: False\n","<keras.layers.merge.Add object at 0x7ff8798c0f28>: False\n","<keras.layers.core.Activation object at 0x7ff8799ebf60>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8798d4fd0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff87987ecc0>: False\n","<keras.layers.core.Activation object at 0x7ff87988def0>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8798942b0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff87984d5f8>: False\n","<keras.layers.core.Activation object at 0x7ff879855c18>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87985cf98>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8798193c8>: False\n","<keras.layers.merge.Add object at 0x7ff8798249e8>: False\n","<keras.layers.core.Activation object at 0x7ff8798f1710>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8797bdf98>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8797e8c88>: False\n","<keras.layers.core.Activation object at 0x7ff8797ef9b0>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff879776d68>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8797a9198>: False\n","<keras.layers.core.Activation object at 0x7ff879737ac8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87979def0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff87976ee48>: False\n","<keras.layers.merge.Add object at 0x7ff879702898>: False\n","<keras.layers.core.Activation object at 0x7ff8797d9278>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87970e898>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8796c37f0>: False\n","<keras.layers.core.Activation object at 0x7ff8796c3e10>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff8796d0860>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff879688be0>: False\n","<keras.layers.core.Activation object at 0x7ff879696978>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87969d710>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff879655a58>: False\n","<keras.layers.merge.Add object at 0x7ff879665d68>: False\n","<keras.layers.core.Activation object at 0x7ff8796217b8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87962bda0>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8795e9978>: False\n","<keras.layers.core.Activation object at 0x7ff879579c50>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87957f3c8>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff879538710>: False\n","<keras.layers.convolutional.Conv2D object at 0x7ff8795f8cf8>: False\n","<keras.layers.pooling.MaxPooling2D object at 0x7ff87953fd30>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff879621780>: False\n","<keras.layers.merge.Add object at 0x7ff87955fac8>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff879505b00>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff87951a748>: False\n","<keras.layers.core.Activation object at 0x7ff87951a940>: False\n","<keras.layers.convolutional.SeparableConv2D object at 0x7ff87950d710>: False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff8794d94a8>: False\n","<keras.layers.core.Activation object at 0x7ff8794e1ac8>: False\n","<keras.layers.core.Flatten object at 0x7ff87970eeb8>: True\n","<keras.layers.core.Dense object at 0x7ff8e36d8ac8>: True\n","<keras.layers.core.Dropout object at 0x7ff878dfe860>: True\n","<keras.layers.core.Dense object at 0x7ff878dfea58>: True\n","<keras.layers.core.Dense object at 0x7ff878df1eb8>: True\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 32768)        0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          4194432     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 32)           4128        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           330         dense_2[0][0]                    \n","==================================================================================================\n","Total params: 25,060,370\n","Trainable params: 4,198,890\n","Non-trainable params: 20,861,480\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/10\n","156/156 [==============================] - 146s 934ms/step - loss: 2.0001 - acc: 0.2679 - val_loss: 1.9447 - val_acc: 0.2237\n","Epoch 2/10\n","156/156 [==============================] - 144s 920ms/step - loss: 1.8243 - acc: 0.3087 - val_loss: 1.9506 - val_acc: 0.2493\n","Epoch 3/10\n","156/156 [==============================] - 142s 910ms/step - loss: 1.8016 - acc: 0.3199 - val_loss: 1.9764 - val_acc: 0.2057\n","Epoch 4/10\n","156/156 [==============================] - 141s 901ms/step - loss: 1.7775 - acc: 0.3253 - val_loss: 1.9679 - val_acc: 0.2554\n","Epoch 5/10\n","156/156 [==============================] - 141s 904ms/step - loss: 1.7601 - acc: 0.3362 - val_loss: 1.9513 - val_acc: 0.2338\n","Epoch 6/10\n","156/156 [==============================] - 140s 895ms/step - loss: 1.7448 - acc: 0.3438 - val_loss: 1.9785 - val_acc: 0.2359\n","Epoch 7/10\n","156/156 [==============================] - 138s 886ms/step - loss: 1.7483 - acc: 0.3379 - val_loss: 1.9528 - val_acc: 0.2356\n","Epoch 8/10\n","156/156 [==============================] - 136s 875ms/step - loss: 1.7367 - acc: 0.3449 - val_loss: 1.9122 - val_acc: 0.2769\n","Epoch 9/10\n","156/156 [==============================] - 136s 874ms/step - loss: 1.7295 - acc: 0.3484 - val_loss: 1.9045 - val_acc: 0.2685\n","Epoch 10/10\n","156/156 [==============================] - 136s 871ms/step - loss: 1.7252 - acc: 0.3523 - val_loss: 1.9446 - val_acc: 0.2348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8mjwVP-cQhff","colab_type":"code","colab":{}},"source":["# Save model with FC layer adapted to modified mnist dataset\n","model.save(\"models/Xception_fully_connected_layer_trained_128_02_32_10.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k793aUcoREWE","colab_type":"code","colab":{}},"source":["# Load model with FC layer adapted to modified mnist dataset\n","from keras.models import load_model \n","model = load_model(\"models/Xception_09624_sgd_learning_rate0001.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ygMPC09Slo1F","colab_type":"text"},"source":["At this point, the top layers are well trained and we can start fine-tuning convolutional layers from Xception. "]},{"cell_type":"code","metadata":{"id":"Sjs2uxdPct1V","colab_type":"code","outputId":"3e5df23b-da86-49e4-a72c-b7ff958daa22","executionInfo":{"status":"ok","timestamp":1573414585549,"user_tz":300,"elapsed":25574,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Visualize layer names and layer indices to see how many layers we should unfreeze for Xception\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["0 input_1 False\n","1 block1_conv1 True\n","2 block1_conv1_bn True\n","3 block1_conv1_act True\n","4 block1_conv2 True\n","5 block1_conv2_bn True\n","6 block1_conv2_act True\n","7 block2_sepconv1 True\n","8 block2_sepconv1_bn True\n","9 block2_sepconv2_act True\n","10 block2_sepconv2 True\n","11 block2_sepconv2_bn True\n","12 conv2d_1 True\n","13 block2_pool True\n","14 batch_normalization_1 True\n","15 add_1 True\n","16 block3_sepconv1_act True\n","17 block3_sepconv1 True\n","18 block3_sepconv1_bn True\n","19 block3_sepconv2_act True\n","20 block3_sepconv2 True\n","21 block3_sepconv2_bn True\n","22 conv2d_2 True\n","23 block3_pool True\n","24 batch_normalization_2 True\n","25 add_2 True\n","26 block4_sepconv1_act True\n","27 block4_sepconv1 True\n","28 block4_sepconv1_bn True\n","29 block4_sepconv2_act True\n","30 block4_sepconv2 True\n","31 block4_sepconv2_bn True\n","32 conv2d_3 True\n","33 block4_pool True\n","34 batch_normalization_3 True\n","35 add_3 True\n","36 block5_sepconv1_act True\n","37 block5_sepconv1 True\n","38 block5_sepconv1_bn True\n","39 block5_sepconv2_act True\n","40 block5_sepconv2 True\n","41 block5_sepconv2_bn True\n","42 block5_sepconv3_act True\n","43 block5_sepconv3 True\n","44 block5_sepconv3_bn True\n","45 add_4 True\n","46 block6_sepconv1_act True\n","47 block6_sepconv1 True\n","48 block6_sepconv1_bn True\n","49 block6_sepconv2_act True\n","50 block6_sepconv2 True\n","51 block6_sepconv2_bn True\n","52 block6_sepconv3_act True\n","53 block6_sepconv3 True\n","54 block6_sepconv3_bn True\n","55 add_5 True\n","56 block7_sepconv1_act True\n","57 block7_sepconv1 True\n","58 block7_sepconv1_bn True\n","59 block7_sepconv2_act True\n","60 block7_sepconv2 True\n","61 block7_sepconv2_bn True\n","62 block7_sepconv3_act True\n","63 block7_sepconv3 True\n","64 block7_sepconv3_bn True\n","65 add_6 True\n","66 block8_sepconv1_act True\n","67 block8_sepconv1 True\n","68 block8_sepconv1_bn True\n","69 block8_sepconv2_act True\n","70 block8_sepconv2 True\n","71 block8_sepconv2_bn True\n","72 block8_sepconv3_act True\n","73 block8_sepconv3 True\n","74 block8_sepconv3_bn True\n","75 add_7 True\n","76 block9_sepconv1_act True\n","77 block9_sepconv1 True\n","78 block9_sepconv1_bn True\n","79 block9_sepconv2_act True\n","80 block9_sepconv2 True\n","81 block9_sepconv2_bn True\n","82 block9_sepconv3_act True\n","83 block9_sepconv3 True\n","84 block9_sepconv3_bn True\n","85 add_8 True\n","86 block10_sepconv1_act True\n","87 block10_sepconv1 True\n","88 block10_sepconv1_bn True\n","89 block10_sepconv2_act True\n","90 block10_sepconv2 True\n","91 block10_sepconv2_bn True\n","92 block10_sepconv3_act True\n","93 block10_sepconv3 True\n","94 block10_sepconv3_bn True\n","95 add_9 True\n","96 block11_sepconv1_act True\n","97 block11_sepconv1 True\n","98 block11_sepconv1_bn True\n","99 block11_sepconv2_act True\n","100 block11_sepconv2 True\n","101 block11_sepconv2_bn True\n","102 block11_sepconv3_act True\n","103 block11_sepconv3 True\n","104 block11_sepconv3_bn True\n","105 add_10 True\n","106 block12_sepconv1_act True\n","107 block12_sepconv1 True\n","108 block12_sepconv1_bn True\n","109 block12_sepconv2_act True\n","110 block12_sepconv2 True\n","111 block12_sepconv2_bn True\n","112 block12_sepconv3_act True\n","113 block12_sepconv3 True\n","114 block12_sepconv3_bn True\n","115 add_11 True\n","116 block13_sepconv1_act True\n","117 block13_sepconv1 True\n","118 block13_sepconv1_bn True\n","119 block13_sepconv2_act True\n","120 block13_sepconv2 True\n","121 block13_sepconv2_bn True\n","122 conv2d_4 True\n","123 block13_pool True\n","124 batch_normalization_4 True\n","125 add_12 True\n","126 block14_sepconv1 True\n","127 block14_sepconv1_bn True\n","128 block14_sepconv1_act True\n","129 block14_sepconv2 True\n","130 block14_sepconv2_bn True\n","131 block14_sepconv2_act True\n","132 flatten_1 True\n","133 dense_1 True\n","134 dropout_1 True\n","135 dense_2 True\n","136 dense_3 True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z0LHOnHsE08J","colab_type":"code","outputId":"a394abd6-aa4f-457b-f095-0284543e0ac8","executionInfo":{"status":"ok","timestamp":1573414396408,"user_tz":300,"elapsed":20368,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Unfreeze all CONV layers in the base model\n","for layer in model.layers[1:]:\n","  layer.trainable = True\n","\n","# Display trainable layers\n","for layer in model.layers:\n","  print(\"{}: {}\".format(layer, layer.trainable))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["<keras.engine.input_layer.InputLayer object at 0x7f7fd1f160b8>: False\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1f16128>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f16160>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f16470>: True\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1f16550>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f16588>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f16710>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f16828>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f16860>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f16ac8>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f16c50>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f16c88>: True\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1f16ef0>: True\n","<keras.layers.pooling.MaxPooling2D object at 0x7f7fd1f1c240>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f1c2e8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f1c400>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f1c438>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f1c470>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f1c6d8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f1c860>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f1c898>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f1cb00>: True\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1f1cc88>: True\n","<keras.layers.pooling.MaxPooling2D object at 0x7f7fd1f1ce10>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f1ceb8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f16fd0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f21048>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f21080>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f212e8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f21470>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f214a8>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f21710>: True\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1f21898>: True\n","<keras.layers.pooling.MaxPooling2D object at 0x7f7fd1f21a20>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f21ac8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f21be0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f21c18>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f21c50>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f21eb8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f1cfd0>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f280b8>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f28320>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f284a8>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f284e0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f28748>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f288d0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f28908>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f28940>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f28ba8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f28d30>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f28d68>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f21fd0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f2d198>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f2d1d0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f2d438>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f2d5c0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f2d5f8>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f2d630>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f2d898>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f2da20>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f2da58>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f2dcc0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f2de48>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f2de80>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f33128>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f332b0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f332e8>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f33320>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f33588>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f33710>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f33748>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f339b0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f33b38>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f33b70>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f33dd8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f33f60>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f33f98>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f28fd0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f38278>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f38400>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f38438>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f386a0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f38828>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f38860>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f38ac8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f38c50>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f38c88>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f38cc0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f38f28>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f33fd0>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f3d128>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f3d390>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f3d518>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f3d550>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f3d7b8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1f3d940>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f3d978>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f3d9b0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f3dc18>: True\n","<keras.layers.core.Activation object at 0x7f7fd1f3dda0>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1f3ddd8>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1f38fd0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec3208>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec3240>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec34a8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1ec3630>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec3668>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec36a0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec3908>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec3a90>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec3ac8>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec3d30>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec3eb8>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec3ef0>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec8198>: True\n","<keras.layers.merge.Add object at 0x7f7fd1ec8320>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec8358>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec8390>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec85f8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ec8780>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec87b8>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec8a20>: True\n","<keras.layers.convolutional.Conv2D object at 0x7f7fd1ec8ba8>: True\n","<keras.layers.pooling.MaxPooling2D object at 0x7f7fd1ec8d30>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ec8dd8>: True\n","<keras.layers.merge.Add object at 0x7f7fd1ec8ef0>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ec8f28>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ece1d0>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ece358>: True\n","<keras.layers.convolutional.SeparableConv2D object at 0x7f7fd1ece390>: True\n","<keras.layers.normalization.BatchNormalization object at 0x7f7fd1ece5f8>: True\n","<keras.layers.core.Activation object at 0x7f7fd1ece780>: True\n","<keras.layers.core.Flatten object at 0x7f7fd1ece7b8>: True\n","<keras.layers.core.Dense object at 0x7f7fd1ece828>: True\n","<keras.layers.core.Dropout object at 0x7f7fd1ece978>: True\n","<keras.layers.core.Dense object at 0x7f7fd1ece9b0>: True\n","<keras.layers.core.Dense object at 0x7f7fd1eceb00>: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mq5-J7lg93Ow","colab_type":"code","outputId":"04229e37-6f65-44db-ec3d-9d5acc267dff","executionInfo":{"status":"ok","timestamp":1573429337532,"user_tz":300,"elapsed":5660007,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Recompile the model for these modifications to take effect. SGD is used with a low learning rate to fine tune.\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","# Print a summary of the model\n","model.summary()\n","\n","# Train model again (this time fine-tuning all Xception blocks alongside the top Dense layers)\n","history = model.fit_generator(datagen.flow(x=x_train, y=y_train, batch_size=batch_size), validation_data=(x_valid,y_valid), steps_per_epoch=len(x_train)//batch_size, epochs=EPOCHS)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 32768)        0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          4194432     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 32)           4128        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           330         dense_2[0][0]                    \n","==================================================================================================\n","Total params: 25,060,370\n","Trainable params: 25,005,842\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","1250/1250 [==============================] - 206s 165ms/step - loss: 0.0632 - acc: 0.9814 - val_loss: 0.1792 - val_acc: 0.9656\n","Epoch 2/30\n","1250/1250 [==============================] - 189s 151ms/step - loss: 0.0613 - acc: 0.9823 - val_loss: 0.1673 - val_acc: 0.9664\n","Epoch 3/30\n","1250/1250 [==============================] - 189s 151ms/step - loss: 0.0627 - acc: 0.9817 - val_loss: 0.1571 - val_acc: 0.9684\n","Epoch 4/30\n","1250/1250 [==============================] - 189s 151ms/step - loss: 0.0518 - acc: 0.9851 - val_loss: 0.1615 - val_acc: 0.9685\n","Epoch 5/30\n","1250/1250 [==============================] - 189s 151ms/step - loss: 0.0532 - acc: 0.9850 - val_loss: 0.1728 - val_acc: 0.9673\n","Epoch 6/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0470 - acc: 0.9871 - val_loss: 0.1640 - val_acc: 0.9693\n","Epoch 7/30\n","1250/1250 [==============================] - 187s 150ms/step - loss: 0.0474 - acc: 0.9865 - val_loss: 0.1567 - val_acc: 0.9707\n","Epoch 8/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0430 - acc: 0.9872 - val_loss: 0.1631 - val_acc: 0.9684\n","Epoch 9/30\n","1250/1250 [==============================] - 187s 150ms/step - loss: 0.0454 - acc: 0.9875 - val_loss: 0.1583 - val_acc: 0.9694\n","Epoch 10/30\n","1250/1250 [==============================] - 187s 150ms/step - loss: 0.0393 - acc: 0.9895 - val_loss: 0.1679 - val_acc: 0.9690\n","Epoch 11/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0432 - acc: 0.9884 - val_loss: 0.1662 - val_acc: 0.9657\n","Epoch 12/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0371 - acc: 0.9898 - val_loss: 0.1625 - val_acc: 0.9689\n","Epoch 13/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0372 - acc: 0.9890 - val_loss: 0.1861 - val_acc: 0.9665\n","Epoch 14/30\n","1250/1250 [==============================] - 186s 149ms/step - loss: 0.0395 - acc: 0.9895 - val_loss: 0.1740 - val_acc: 0.9665\n","Epoch 15/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0329 - acc: 0.9908 - val_loss: 0.1701 - val_acc: 0.9689\n","Epoch 16/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0306 - acc: 0.9908 - val_loss: 0.1700 - val_acc: 0.9688\n","Epoch 17/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0325 - acc: 0.9909 - val_loss: 0.1658 - val_acc: 0.9704\n","Epoch 18/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0292 - acc: 0.9920 - val_loss: 0.1721 - val_acc: 0.9704\n","Epoch 19/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0283 - acc: 0.9920 - val_loss: 0.1862 - val_acc: 0.9676\n","Epoch 20/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0301 - acc: 0.9919 - val_loss: 0.1760 - val_acc: 0.9704\n","Epoch 21/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0296 - acc: 0.9920 - val_loss: 0.1772 - val_acc: 0.9691\n","Epoch 22/30\n","1250/1250 [==============================] - 187s 150ms/step - loss: 0.0325 - acc: 0.9915 - val_loss: 0.1805 - val_acc: 0.9680\n","Epoch 23/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.1712 - val_acc: 0.9700\n","Epoch 24/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.1836 - val_acc: 0.9685\n","Epoch 25/30\n","1250/1250 [==============================] - 187s 149ms/step - loss: 0.0265 - acc: 0.9924 - val_loss: 0.1817 - val_acc: 0.9701\n","Epoch 26/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0253 - acc: 0.9933 - val_loss: 0.1822 - val_acc: 0.9696\n","Epoch 27/30\n","1250/1250 [==============================] - 188s 151ms/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.1861 - val_acc: 0.9699\n","Epoch 28/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0250 - acc: 0.9930 - val_loss: 0.1865 - val_acc: 0.9694\n","Epoch 29/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0249 - acc: 0.9924 - val_loss: 0.1738 - val_acc: 0.9698\n","Epoch 30/30\n","1250/1250 [==============================] - 188s 150ms/step - loss: 0.0199 - acc: 0.9943 - val_loss: 0.1802 - val_acc: 0.9712\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t6M4RQtAxASM","colab_type":"code","colab":{}},"source":["# Save the model\n","model.save('models/Xception_{0}_sgd_lr{1}_{2}epochs_bs{3}.h5'.format(max(history.history['val_acc']), learning_rate, EPOCHS, batch_size))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kLih_DG8SuT","colab_type":"code","outputId":"08257c88-96c0-42b9-95c8-c243e206441d","executionInfo":{"status":"ok","timestamp":1573413661273,"user_tz":300,"elapsed":21923,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Plot history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.savefig('plots/Xception_{0}acc_sgd_lr{1}_{2}epochs_bs{3}.png'.format(max(history.history['val_acc']), learning_rate, EPOCHS, batch_size))\n","plt.show()"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmjfgHlbgMqjpoQ3AAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6Odo_rjm8T37","colab_type":"code","outputId":"7a3ffc09-4b82-462a-eb47-0b3c4a7e9850","executionInfo":{"status":"ok","timestamp":1573413661460,"user_tz":300,"elapsed":22100,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Plot history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.savefig('plots/Xception_{0}loss_sgd_lr{1}_{2}epochs_bs{3}.png'.format(min(history.history['val_loss']), learning_rate, EPOCHS, batch_size))\n","plt.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"XNc9wtQHt3Gj","colab_type":"code","outputId":"bd3dc5e2-71c0-4efa-d71a-630bf8e93042","executionInfo":{"status":"ok","timestamp":1573351014451,"user_tz":300,"elapsed":3970426,"user":{"displayName":"Michael Li","photoUrl":"","userId":"09890785565284515634"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Load full dataset to train final model \n","x_train = pd.read_pickle(\"data/preprocessed_train_max_x.pkl\")\n","y_train = pd.read_csv(\"data/train_max_y.csv\")[\"Label\"]\n","\n","# Transform data from grayscale to rgb (3 channels)\n","x_train = np.stack((x_train,x_train,x_train), axis=-1)\n","\n","# Load final model\n","from keras.models import load_model\n","model = load_model(\"models/Xception_sgd0.9737_learning_rate0.0005.h5\")\n","\n","# Fit on entire dataset\n","history = model.fit_generator(datagen.flow(x=x_train, y=y_train, batch_size=batch_size), steps_per_epoch=len(x_train)//batch_size, epochs=EPOCHS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","195/195 [==============================] - 133s 682ms/step - loss: 0.0737 - acc: 0.9841\n","Epoch 2/30\n","195/195 [==============================] - 129s 664ms/step - loss: 0.0685 - acc: 0.9842\n","Epoch 3/30\n","195/195 [==============================] - 130s 667ms/step - loss: 0.0621 - acc: 0.9856\n","Epoch 4/30\n","195/195 [==============================] - 130s 668ms/step - loss: 0.0617 - acc: 0.9857\n","Epoch 5/30\n","195/195 [==============================] - 129s 662ms/step - loss: 0.0589 - acc: 0.9859\n","Epoch 6/30\n","195/195 [==============================] - 130s 668ms/step - loss: 0.0539 - acc: 0.9864\n","Epoch 7/30\n","195/195 [==============================] - 130s 667ms/step - loss: 0.0529 - acc: 0.9871\n","Epoch 8/30\n","195/195 [==============================] - 129s 664ms/step - loss: 0.0515 - acc: 0.9874\n","Epoch 9/30\n","195/195 [==============================] - 130s 666ms/step - loss: 0.0507 - acc: 0.9878\n","Epoch 10/30\n","195/195 [==============================] - 129s 663ms/step - loss: 0.0503 - acc: 0.9878\n","Epoch 11/30\n","195/195 [==============================] - 129s 660ms/step - loss: 0.0498 - acc: 0.9875\n","Epoch 12/30\n","195/195 [==============================] - 130s 669ms/step - loss: 0.0474 - acc: 0.9885\n","Epoch 13/30\n","195/195 [==============================] - 130s 665ms/step - loss: 0.0467 - acc: 0.9881\n","Epoch 14/30\n","195/195 [==============================] - 131s 671ms/step - loss: 0.0483 - acc: 0.9880\n","Epoch 15/30\n","195/195 [==============================] - 130s 666ms/step - loss: 0.0419 - acc: 0.9889\n","Epoch 16/30\n","195/195 [==============================] - 129s 663ms/step - loss: 0.0455 - acc: 0.9886\n","Epoch 17/30\n","195/195 [==============================] - 129s 660ms/step - loss: 0.0434 - acc: 0.9890\n","Epoch 18/30\n","195/195 [==============================] - 129s 664ms/step - loss: 0.0404 - acc: 0.9898\n","Epoch 19/30\n","195/195 [==============================] - 130s 666ms/step - loss: 0.0427 - acc: 0.9891\n","Epoch 20/30\n","195/195 [==============================] - 130s 669ms/step - loss: 0.0402 - acc: 0.9894\n","Epoch 21/30\n","195/195 [==============================] - 129s 664ms/step - loss: 0.0383 - acc: 0.9896\n","Epoch 22/30\n","195/195 [==============================] - 129s 660ms/step - loss: 0.0378 - acc: 0.9905\n","Epoch 23/30\n","195/195 [==============================] - 128s 658ms/step - loss: 0.0343 - acc: 0.9908\n","Epoch 24/30\n","195/195 [==============================] - 129s 662ms/step - loss: 0.0402 - acc: 0.9898\n","Epoch 25/30\n","195/195 [==============================] - 130s 665ms/step - loss: 0.0330 - acc: 0.9914\n","Epoch 26/30\n","195/195 [==============================] - 129s 660ms/step - loss: 0.0408 - acc: 0.9895\n","Epoch 27/30\n","195/195 [==============================] - 128s 658ms/step - loss: 0.0320 - acc: 0.9916\n","Epoch 28/30\n","195/195 [==============================] - 129s 663ms/step - loss: 0.0343 - acc: 0.9906\n","Epoch 29/30\n","195/195 [==============================] - 128s 656ms/step - loss: 0.0339 - acc: 0.9908\n","Epoch 30/30\n","195/195 [==============================] - 129s 660ms/step - loss: 0.0287 - acc: 0.9924\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbb620dab00>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"414psWl4uqif","colab_type":"code","colab":{}},"source":["# Save final model \n","model.save('models/Xception_final.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"14-zfAxp4Iun","colab_type":"code","colab":{}},"source":["def predict(model):\n","  \"\"\"Method that takes as input a model and stores its predictions in a csv file.\"\"\"\n","  import datetime\n","\n","  test_img = pd.read_pickle(\"data/preprocessed_test_max_x.pkl\")\n","\n","  # Convert tests images from grayscale to rgb (3 channels)\n","  test_img = np.stack((test_img,test_img,test_img), axis=-1)\n","\n","  # Predict \n","  preds = model.predict(test_img).argmax(axis=-1)\n","\n","  # Create DataFrame with predictions\n","  df = pd.DataFrame({\"Id\": list(range(len(preds))), \"Label\": preds})\n","\n","  # Save predictions \n","  df.to_csv(\"predictions/predictions{}.csv\".format(datetime.datetime.now()), index=False)\n","\n","  return preds "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9ALxhj2OUb1","colab_type":"code","colab":{}},"source":["# Generate predictions\n","preds = predict(model)"],"execution_count":0,"outputs":[]}]}