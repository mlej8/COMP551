{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG19_CIFAR10.ipynb","provenance":[{"file_id":"1VBi9Gz0Af_UIn28kk3oqtCd-xPIkB1NZ","timestamp":1575759561959}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4DoTXjHY9AhT","colab_type":"text"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"pCXl9FE98-I6","colab_type":"code","outputId":"89d52244-a934-4466-d486-2f2b9d929523","executionInfo":{"status":"ok","timestamp":1576188664212,"user_tz":300,"elapsed":24202,"user":{"displayName":"Michael Li","photoUrl":"","userId":"10697481005704992704"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["# Mounting Google Drive locally\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbx4BW7X8-tD","colab_type":"code","colab":{}},"source":["# Navigate to folder containing project\n","import os\n","os.chdir(\"drive/My Drive/COMP 551 Project 4/\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQLr_TzC9DvE","colab_type":"text"},"source":["#VGG19 on CIFAR 10\n"]},{"cell_type":"code","metadata":{"id":"H903pUy51T2V","colab_type":"code","outputId":"ca7f2f57-c4fe-4841-83da-14af45c9a615","executionInfo":{"status":"ok","timestamp":1576188667246,"user_tz":300,"elapsed":26654,"user":{"displayName":"Michael Li","photoUrl":"","userId":"10697481005704992704"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["# Import datasets directly from keras \n","from keras.datasets import cifar10\n","from keras.applications.vgg19 import VGG19\n","from keras import optimizers\n","from keras.layers import Input\n","from keras.callbacks import CSVLogger"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0ZgWAZiD4fDX","colab_type":"code","outputId":"1e05564d-5511-4609-f1b1-3533ffe580dd","executionInfo":{"status":"ok","timestamp":1576188680870,"user_tz":300,"elapsed":40117,"user":{"displayName":"Michael Li","photoUrl":"","userId":"10697481005704992704"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Load data\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5cfC5p8G8501","colab_type":"code","colab":{}},"source":["from google.colab.patches import cv2_imshow\n","# Function to show a single image \n","def show_single_picture(img):\n","    \"\"\" Plot an image \"\"\"\n","    cv2_imshow(img*255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cwke3WTR93JW","colab_type":"code","outputId":"56b54529-aab8-42db-e61b-54ec3306283e","executionInfo":{"status":"ok","timestamp":1576188681152,"user_tz":300,"elapsed":39317,"user":{"displayName":"Michael Li","photoUrl":"","userId":"10697481005704992704"}},"colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["# Peek image\n","show_single_picture(x_train[0])"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZklEQVR4nAXB2Y8cSZ0A4Dh+EZER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\nAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=32x32 at 0x7FA3E27D94E0>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Uoxx0u_a-ELv","colab_type":"code","colab":{}},"source":["# Save data properties \n","img_size = x_train[0].shape[0]\n","num_channels = x_train[0].shape[2]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccrFot684XQD","colab_type":"code","colab":{}},"source":["# Experimental data\n","EPOCHS = 50\n","batch_sizes = [16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320]\n","bs_simplified = [32, 96, 128, 160, 192, 224, 256, 320]\n","# [16, 32, 64, 96, 128, 160, 192, 224, 256, 320]\n","# bs = bs_simplified[0]\n","learning_rates =  [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20]\n","lr_simplified = [0.01, 0.02, 0.03, 0.05, 0.075, 0.10, 0.125, 0.15, 0.18, 0.20]\n","lr = lr_simplified[6]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ma-RmK064key","colab_type":"code","outputId":"b22309dd-d3e2-4982-ec4b-0f6205f17eb0","executionInfo":{"status":"ok","timestamp":1576180155353,"user_tz":300,"elapsed":9046768,"user":{"displayName":"Michael Li","photoUrl":"","userId":"10697481005704992704"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for bs in bs_simplified:\n","  print(\"Batch Size: {}\\nLearning Rate: {}\".format(bs, lr))  \n","  # Create VGG model\n","  vgg = VGG19(weights=None, include_top=True, input_shape=(img_size,img_size,num_channels))\n","  # Customize SGD optimizer with Generalization Bound \n","  sgd = optimizers.SGD(lr=lr, momentum=0.0, nesterov=False)\n","  # Compile the model (should be done ***after*** setting layers to non-trainable)\n","  vgg.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","  # Print a summary of the model\n","  vgg.summary()\n","\n","  # Create a CSV Logger\n","  csv_logger = CSVLogger(\"Results/VGG19CIFAR10/batch_size{}_learning_rate{}.csv\".format(bs, lr))\n","\n","  # Train ResNet using fix learning rate for multiple batch size \n","  history = vgg.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=bs, \n","                    epochs=EPOCHS, verbose=1, callbacks=[csv_logger], use_multiprocessing=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch Size: 32\n","Learning Rate: 0.125\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","50000/50000 [==============================] - 163s 3ms/step - loss: 14.4860 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 2/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 3/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 4/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 5/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 6/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 7/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 8/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 9/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 10/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 11/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 12/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 13/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 14/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 15/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 16/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 17/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 18/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 19/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 20/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 21/50\n","50000/50000 [==============================] - 153s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 22/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 23/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 24/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 25/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 26/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 27/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 28/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 29/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 30/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 31/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 32/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 33/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 34/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 35/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 36/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 37/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 38/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 39/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 40/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 41/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 42/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 43/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 44/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 45/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 46/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 47/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 48/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 49/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 50/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Batch Size: 96\n","Learning Rate: 0.125\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 85s 2ms/step - loss: 14.4437 - acc: 0.0996 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 2/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 3/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 4/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 5/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 6/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 7/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 8/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 9/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 10/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 11/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 12/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 13/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 14/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 15/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 16/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 17/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 18/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 19/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 20/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 21/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 22/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 23/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 24/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 25/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 26/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 27/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 28/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 29/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 30/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 31/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 32/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 33/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 34/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 35/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 36/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 37/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 38/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 39/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 40/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 41/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 42/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 43/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 44/50\n","50000/50000 [==============================] - 80s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 45/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 46/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 47/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 48/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 49/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Epoch 50/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 14.5064 - acc: 0.1000 - val_loss: 14.5064 - val_acc: 0.1000\n","Batch Size: 128\n","Learning Rate: 0.125\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 73s 1ms/step - loss: 3.7940 - acc: 0.1010 - val_loss: 3.6094 - val_acc: 0.1000\n","Epoch 2/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6057 - acc: 0.1001 - val_loss: 3.6211 - val_acc: 0.1000\n","Epoch 3/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6033 - acc: 0.1014 - val_loss: 3.6010 - val_acc: 0.1000\n","Epoch 4/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6021 - acc: 0.1006 - val_loss: 3.6185 - val_acc: 0.1000\n","Epoch 5/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6022 - acc: 0.0992 - val_loss: 3.6119 - val_acc: 0.1000\n","Epoch 6/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6003 - acc: 0.1001 - val_loss: 3.6141 - val_acc: 0.1000\n","Epoch 7/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6001 - acc: 0.0997 - val_loss: 3.6095 - val_acc: 0.1000\n","Epoch 8/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5996 - acc: 0.0982 - val_loss: 3.5990 - val_acc: 0.1000\n","Epoch 9/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5991 - acc: 0.0994 - val_loss: 3.5973 - val_acc: 0.1000\n","Epoch 10/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5989 - acc: 0.0992 - val_loss: 3.5968 - val_acc: 0.1000\n","Epoch 11/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5976 - acc: 0.1016 - val_loss: 3.5987 - val_acc: 0.1000\n","Epoch 12/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5980 - acc: 0.0993 - val_loss: 3.6039 - val_acc: 0.1000\n","Epoch 13/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5977 - acc: 0.0982 - val_loss: 3.6001 - val_acc: 0.1000\n","Epoch 14/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5973 - acc: 0.1009 - val_loss: 3.6026 - val_acc: 0.1000\n","Epoch 15/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5891 - acc: 0.1088 - val_loss: 3.5360 - val_acc: 0.1579\n","Epoch 16/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.6036 - acc: 0.1060 - val_loss: 3.5965 - val_acc: 0.1000\n","Epoch 17/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5966 - acc: 0.1015 - val_loss: 3.6065 - val_acc: 0.1000\n","Epoch 18/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5967 - acc: 0.0992 - val_loss: 3.5980 - val_acc: 0.1000\n","Epoch 19/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5960 - acc: 0.1002 - val_loss: 3.5973 - val_acc: 0.1000\n","Epoch 20/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5959 - acc: 0.0988 - val_loss: 3.6038 - val_acc: 0.1000\n","Epoch 21/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5961 - acc: 0.0991 - val_loss: 3.6005 - val_acc: 0.1000\n","Epoch 22/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5958 - acc: 0.0978 - val_loss: 3.5953 - val_acc: 0.1000\n","Epoch 23/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5958 - acc: 0.0998 - val_loss: 3.5917 - val_acc: 0.1000\n","Epoch 24/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5952 - acc: 0.0993 - val_loss: 3.6003 - val_acc: 0.1000\n","Epoch 25/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5955 - acc: 0.0991 - val_loss: 3.5977 - val_acc: 0.1000\n","Epoch 26/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5950 - acc: 0.1005 - val_loss: 3.5978 - val_acc: 0.1000\n","Epoch 27/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5952 - acc: 0.1015 - val_loss: 3.5961 - val_acc: 0.1000\n","Epoch 28/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5952 - acc: 0.1006 - val_loss: 3.5964 - val_acc: 0.1000\n","Epoch 29/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5951 - acc: 0.0960 - val_loss: 3.5974 - val_acc: 0.1000\n","Epoch 30/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5955 - acc: 0.0991 - val_loss: 3.5967 - val_acc: 0.1000\n","Epoch 31/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5945 - acc: 0.1004 - val_loss: 3.5977 - val_acc: 0.1000\n","Epoch 32/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5947 - acc: 0.0994 - val_loss: 3.5948 - val_acc: 0.1000\n","Epoch 33/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5946 - acc: 0.1016 - val_loss: 3.5951 - val_acc: 0.1000\n","Epoch 34/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5952 - acc: 0.1001 - val_loss: 3.5927 - val_acc: 0.1000\n","Epoch 35/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5951 - acc: 0.0998 - val_loss: 3.5949 - val_acc: 0.1000\n","Epoch 36/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5946 - acc: 0.0991 - val_loss: 3.5915 - val_acc: 0.1000\n","Epoch 37/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5941 - acc: 0.1012 - val_loss: 3.5996 - val_acc: 0.1000\n","Epoch 38/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5942 - acc: 0.1013 - val_loss: 3.5964 - val_acc: 0.1000\n","Epoch 39/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5943 - acc: 0.1005 - val_loss: 3.5944 - val_acc: 0.1000\n","Epoch 40/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5940 - acc: 0.1011 - val_loss: 3.5978 - val_acc: 0.1000\n","Epoch 41/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5944 - acc: 0.0971 - val_loss: 3.5937 - val_acc: 0.1000\n","Epoch 42/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5943 - acc: 0.0991 - val_loss: 3.5955 - val_acc: 0.1000\n","Epoch 43/50\n","50000/50000 [==============================] - 70s 1ms/step - loss: 3.5945 - acc: 0.0996 - val_loss: 3.5936 - val_acc: 0.1000\n","Epoch 44/50\n","49920/50000 [============================>.] - ETA: 0s - loss: 3.5946 - acc: 0.1003"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-62b5a921940a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Train ResNet using fix learning rate for multiple batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   history = vgg.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=bs, \n\u001b[0;32m---> 18\u001b[0;31m                     epochs=EPOCHS, verbose=1, callbacks=[csv_logger], use_multiprocessing=True)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    219\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d3sGUvzpvCBD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}