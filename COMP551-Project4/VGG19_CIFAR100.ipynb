{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG19_CIFAR100.ipynb","provenance":[{"file_id":"1SV1Y4MNg-QBdvpTCO87B7NqcC4yTHWv0","timestamp":1575759689294},{"file_id":"1VBi9Gz0Af_UIn28kk3oqtCd-xPIkB1NZ","timestamp":1575759561959}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4DoTXjHY9AhT","colab_type":"text"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"pCXl9FE98-I6","colab_type":"code","outputId":"f5ef2186-fa32-43d4-b785-c47930620133","executionInfo":{"status":"ok","timestamp":1576348595606,"user_tz":-120,"elapsed":16371,"user":{"displayName":"Aly Elgharabawy","photoUrl":"","userId":"09197803075685430722"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Mounting Google Drive locally\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cSDK7Fh3sSFK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"45dca3c4-fe08-4997-d555-18786b845424","executionInfo":{"status":"ok","timestamp":1576348611309,"user_tz":-120,"elapsed":934,"user":{"displayName":"Aly Elgharabawy","photoUrl":"","userId":"09197803075685430722"}}},"source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["'Copy for Victor - ResNet50V2_CIFAR10.ipynb'\t   ResNet50V2_CIFAR100.ipynb\n","'Copy of Ding ResNet50V2_CIFAR100.ipynb'\t   ResNet50V2_CIFAR10.ipynb\n","'Copy of ErJunFootball ResNet50V2_CIFAR10.ipynb'   Results\n","'Copy of Michael ResNet50V2_CIFAR100.ipynb'\t   TODO.gdoc\n","'Copy of Stella ResNet50V2_CIFAR10.ipynb'\t   VGG19_CIFAR100.ipynb\n","'Copy of Tony ResNet50V2_CIFAR100.ipynb'\t   VGG19_CIFAR10.ipynb\n"," Data\t\t\t\t\t\t   vm-private-key.ppk\n"," data_visualization.ipynb\t\t\t   vm-public-key\n"," load_datasets.ipynb\t\t\t\t  'VM ResNet50V2_CIFAR10.ipynb'\n"," Papers\t\t\t\t\t\t   WILLIAM\n"," Plots\t\t\t\t\t\t  'Work Distribution.gdoc'\n"," pytorch_cifar.ipynb\t\t\t\t   Xception_CIFAR100.ipynb\n","'Research Paper.gdoc'\t\t\t\t   Xception_CIFAR10.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbx4BW7X8-tD","colab_type":"code","colab":{}},"source":["# Navigate to folder containing project\n","import os\n","os.chdir(\"/content/drive/My Drive/COMP 551 Project 4/Results/VGG19CIFAR100_200EPOCHS\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fvDhjg8tIJz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"1830e6a1-1f91-4eb9-fc7d-61f9f0f57944","executionInfo":{"status":"ok","timestamp":1576348794311,"user_tz":-120,"elapsed":1232,"user":{"displayName":"Aly Elgharabawy","photoUrl":"","userId":"09197803075685430722"}}},"source":["!unzip cifar100-20191214T181928Z-001.zip"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Archive:  cifar100-20191214T181928Z-001.zip\n","   creating: cifar100/_ipynb_checkpoints/\n","  inflating: cifar100/log_lr0.1_bs160.txt  \n","  inflating: cifar100/log_lr0.1_bs224.txt  \n","  inflating: cifar100/log_lr0.1_bs192.txt  \n","  inflating: cifar100/log_lr0.1_bs256.txt  \n","  inflating: cifar100/missing results.txt  \n","  inflating: cifar100/log_lr0.1_bs320.txt  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VQLr_TzC9DvE","colab_type":"text"},"source":["#VGG19 on CIFAR 100\n"]},{"cell_type":"code","metadata":{"id":"H903pUy51T2V","colab_type":"code","outputId":"41409399-d7f0-42a3-8929-8743220071f7","executionInfo":{"status":"ok","timestamp":1576166893112,"user_tz":300,"elapsed":2536,"user":{"displayName":"Stella Liu","photoUrl":"","userId":"11769173049742611731"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["# Import datasets directly from keras \n","from keras.datasets import cifar100\n","from keras.applications.vgg19 import VGG19\n","from keras import optimizers\n","from keras.layers import Input\n","from keras.callbacks import CSVLogger"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0ZgWAZiD4fDX","colab_type":"code","outputId":"4fff1780-a034-4e6c-bff4-ff182df8cc32","executionInfo":{"status":"ok","timestamp":1576166901887,"user_tz":300,"elapsed":11301,"user":{"displayName":"Stella Liu","photoUrl":"","userId":"11769173049742611731"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Load data\n","(x_train, y_train), (x_test, y_test) = cifar100.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 6s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5cfC5p8G8501","colab_type":"code","colab":{}},"source":["from google.colab.patches import cv2_imshow\n","# Function to show a single image \n","def show_single_picture(img):\n","    \"\"\" Plot an image \"\"\"\n","    cv2_imshow(img*255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cwke3WTR93JW","colab_type":"code","outputId":"7fcfabbb-47f2-4ce4-a785-0c35c78dfbcf","executionInfo":{"status":"ok","timestamp":1576166902190,"user_tz":300,"elapsed":11589,"user":{"displayName":"Stella Liu","photoUrl":"","userId":"11769173049742611731"}},"colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["# Peek image\n","show_single_picture(x_train[0])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZ0lEQVR4nJXQyZNdZRkG8G8683TP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\nnQAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=32x32 at 0x7F47C6AE8940>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Uoxx0u_a-ELv","colab_type":"code","colab":{}},"source":["# Save data properties \n","img_size = x_train[0].shape[0]\n","num_channels = x_train[0].shape[2]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccrFot684XQD","colab_type":"code","colab":{}},"source":["# Experimental data\n","EPOCHS = 50\n","WARMUP = 10\n","WARMUP_LR = 0.1\n","batch_sizes = [16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320]\n","bs_simplified = [16, 32, 64, 96, 128, 160, 192, 224, 256, 320]\n","# bs = bs_simplified[0]\n","learning_rates =  [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20]\n","lr_simplified = [0.01, 0.02, 0.03, 0.05, 0.075, 0.10, 0.12, 0.15, 0.18, 0.20]\n","lr = lr_simplified[4]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1va2fpkcJew","colab_type":"code","outputId":"f0cf0a86-e904-4778-9942-9928b01c4c85","executionInfo":{"status":"error","timestamp":1576098925402,"user_tz":300,"elapsed":440436,"user":{"displayName":"Yu Yun Liu","photoUrl":"","userId":"00737499092832623865"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Looping over batch sizes using fixed learning rate \n","for batch_size in bs_simplified:\n","  print(\"Batch Size: {}\\nLearning Rate: {}\".format(batch_size, lr))\n","  # Create ResNet model\n","  vgg = VGG19(weights=None, include_top=True, input_shape=(img_size,img_size,num_channels))\n","   \n","  # Compile the model (should be done ***after*** setting layers to non-trainable)\n","  vgg.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","  # Print a summary of the model\n","  vgg.summary()\n","\n","  # Customize SGD optimizer with Generalization Bound \n","  sgd = optimizers.SGD(lr=lr, momentum=0.0, nesterov=False)\n","\n","  # Create a CSV Logger\n","  csv_logger = CSVLogger(\"Results/VGG19CIFAR100/batch_size{}_learning_rate{}.csv\".format(batch_size, lr), separator=',', append=False)\n","\n","  # Train ResNet using fix learning rate for multiple batch size \n","  history = vgg.fit(x=x_train, y=y_train, validation_data=(x_test, y_test),batch_size=batch_size, epochs=EPOCHS, verbose=1, use_multiprocessing=True, callbacks=[csv_logger])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch Size: 16\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 270s 5ms/step - loss: 4.8124 - acc: 0.0096 - val_loss: 4.6684 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 4.6662 - acc: 0.0091 - val_loss: 4.6482 - val_acc: 0.0100\n","Epoch 3/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 4.6530 - acc: 0.0102 - val_loss: 4.6441 - val_acc: 0.0100\n","Epoch 4/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 4.6448 - acc: 0.0101 - val_loss: 4.6456 - val_acc: 0.0100\n","Epoch 5/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 4.6403 - acc: 0.0095 - val_loss: 4.6323 - val_acc: 0.0100\n","Epoch 6/50\n","50000/50000 [==============================] - 269s 5ms/step - loss: 4.6372 - acc: 0.0095 - val_loss: 4.6387 - val_acc: 0.0100\n","Epoch 7/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 4.6364 - acc: 0.0090 - val_loss: 4.6354 - val_acc: 0.0100\n","Epoch 8/50\n","50000/50000 [==============================] - 269s 5ms/step - loss: 4.6349 - acc: 0.0100 - val_loss: 4.6299 - val_acc: 0.0100\n","Epoch 9/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 4.6333 - acc: 0.0100 - val_loss: 4.6254 - val_acc: 0.0100\n","Epoch 10/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 4.6312 - acc: 0.0107 - val_loss: 4.6249 - val_acc: 0.0100\n","Epoch 11/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 4.6297 - acc: 0.0102 - val_loss: 4.6355 - val_acc: 0.0100\n","Epoch 12/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 4.6175 - acc: 0.0120 - val_loss: 4.5294 - val_acc: 0.0188\n","Epoch 13/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 4.5417 - acc: 0.0166 - val_loss: 4.5901 - val_acc: 0.0196\n","Epoch 14/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 4.3954 - acc: 0.0242 - val_loss: 4.2987 - val_acc: 0.0298\n","Epoch 15/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 4.2704 - acc: 0.0339 - val_loss: 4.1621 - val_acc: 0.0450\n","Epoch 16/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 4.1144 - acc: 0.0515 - val_loss: 4.2231 - val_acc: 0.0492\n","Epoch 17/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 4.0133 - acc: 0.0656 - val_loss: 4.0288 - val_acc: 0.0696\n","Epoch 18/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.9441 - acc: 0.0758 - val_loss: 3.9006 - val_acc: 0.0912\n","Epoch 19/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.8738 - acc: 0.0869 - val_loss: 3.9782 - val_acc: 0.0798\n","Epoch 20/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.8101 - acc: 0.0964 - val_loss: 3.7348 - val_acc: 0.1153\n","Epoch 21/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.7871 - acc: 0.1062 - val_loss: 3.7199 - val_acc: 0.1228\n","Epoch 22/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.7486 - acc: 0.1127 - val_loss: 3.7509 - val_acc: 0.1204\n","Epoch 23/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 3.7588 - acc: 0.1159 - val_loss: 3.9685 - val_acc: 0.1026\n","Epoch 24/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.7443 - acc: 0.1198 - val_loss: 3.6366 - val_acc: 0.1364\n","Epoch 25/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 3.8024 - acc: 0.1140 - val_loss: 3.7959 - val_acc: 0.1150\n","Epoch 26/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 3.8791 - acc: 0.1001 - val_loss: 3.9102 - val_acc: 0.0906\n","Epoch 27/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 3.9437 - acc: 0.0942 - val_loss: 3.9567 - val_acc: 0.0837\n","Epoch 28/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.4637 - acc: 0.0127 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 29/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 30/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 31/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 32/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 33/50\n","50000/50000 [==============================] - 268s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 34/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 35/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 36/50\n","50000/50000 [==============================] - 265s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 37/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 38/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 39/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 40/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 41/50\n","50000/50000 [==============================] - 266s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 42/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 43/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 44/50\n","50000/50000 [==============================] - 267s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 45/50\n","50000/50000 [==============================] - 270s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 46/50\n","50000/50000 [==============================] - 271s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 47/50\n","50000/50000 [==============================] - 272s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 48/50\n","50000/50000 [==============================] - 272s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 49/50\n","50000/50000 [==============================] - 270s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 50/50\n","50000/50000 [==============================] - 271s 5ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Batch Size: 32\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 5.0572 - acc: 0.0099 - val_loss: 4.8841 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7877 - acc: 0.0100 - val_loss: 4.7516 - val_acc: 0.0100\n","Epoch 3/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7577 - acc: 0.0098 - val_loss: 4.7563 - val_acc: 0.0100\n","Epoch 4/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7513 - acc: 0.0098 - val_loss: 4.7553 - val_acc: 0.0100\n","Epoch 5/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7463 - acc: 0.0098 - val_loss: 4.7479 - val_acc: 0.0100\n","Epoch 6/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.7434 - acc: 0.0102 - val_loss: 4.7391 - val_acc: 0.0100\n","Epoch 7/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7404 - acc: 0.0099 - val_loss: 4.7394 - val_acc: 0.0100\n","Epoch 8/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7385 - acc: 0.0103 - val_loss: 4.7333 - val_acc: 0.0100\n","Epoch 9/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7383 - acc: 0.0097 - val_loss: 4.7347 - val_acc: 0.0100\n","Epoch 10/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.7364 - acc: 0.0103 - val_loss: 4.7307 - val_acc: 0.0100\n","Epoch 11/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7352 - acc: 0.0095 - val_loss: 4.7307 - val_acc: 0.0100\n","Epoch 12/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7341 - acc: 0.0102 - val_loss: 4.7317 - val_acc: 0.0100\n","Epoch 13/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.7331 - acc: 0.0098 - val_loss: 4.7284 - val_acc: 0.0100\n","Epoch 14/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 4.7335 - acc: 0.0093 - val_loss: 4.7305 - val_acc: 0.0100\n","Epoch 15/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.7318 - acc: 0.0095 - val_loss: 4.7274 - val_acc: 0.0100\n","Epoch 16/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.7271 - acc: 0.0106 - val_loss: 4.6960 - val_acc: 0.0100\n","Epoch 17/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 4.6348 - acc: 0.0108 - val_loss: 4.6242 - val_acc: 0.0083\n","Epoch 18/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 4.5435 - acc: 0.0165 - val_loss: 4.4414 - val_acc: 0.0194\n","Epoch 19/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.3094 - acc: 0.0336 - val_loss: 4.2929 - val_acc: 0.0332\n","Epoch 20/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 4.0586 - acc: 0.0624 - val_loss: 4.0486 - val_acc: 0.0671\n","Epoch 21/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 3.8987 - acc: 0.0888 - val_loss: 3.9729 - val_acc: 0.0829\n","Epoch 22/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 3.7529 - acc: 0.1127 - val_loss: 3.7787 - val_acc: 0.1197\n","Epoch 23/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.6150 - acc: 0.1411 - val_loss: 3.9809 - val_acc: 0.1152\n","Epoch 24/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.4669 - acc: 0.1660 - val_loss: 3.5874 - val_acc: 0.1477\n","Epoch 25/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 3.3257 - acc: 0.1901 - val_loss: 3.4502 - val_acc: 0.1827\n","Epoch 26/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.1928 - acc: 0.2159 - val_loss: 3.3677 - val_acc: 0.1983\n","Epoch 27/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.0733 - acc: 0.2408 - val_loss: 3.2202 - val_acc: 0.2236\n","Epoch 28/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.9690 - acc: 0.2628 - val_loss: 3.2277 - val_acc: 0.2264\n","Epoch 29/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 2.8690 - acc: 0.2830 - val_loss: 3.1978 - val_acc: 0.2419\n","Epoch 30/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.7859 - acc: 0.3005 - val_loss: 3.4915 - val_acc: 0.2098\n","Epoch 31/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.7222 - acc: 0.3128 - val_loss: 3.0828 - val_acc: 0.2553\n","Epoch 32/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.6637 - acc: 0.3272 - val_loss: 3.1666 - val_acc: 0.2507\n","Epoch 33/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.6297 - acc: 0.3314 - val_loss: 3.1806 - val_acc: 0.2546\n","Epoch 34/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 2.5988 - acc: 0.3402 - val_loss: 3.2000 - val_acc: 0.2562\n","Epoch 35/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.5967 - acc: 0.3429 - val_loss: 3.0850 - val_acc: 0.2710\n","Epoch 36/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.5937 - acc: 0.3467 - val_loss: 3.3544 - val_acc: 0.2475\n","Epoch 37/50\n","50000/50000 [==============================] - 159s 3ms/step - loss: 2.6125 - acc: 0.3418 - val_loss: 3.0882 - val_acc: 0.2720\n","Epoch 38/50\n","50000/50000 [==============================] - 159s 3ms/step - loss: 2.6456 - acc: 0.3396 - val_loss: 3.2143 - val_acc: 0.2531\n","Epoch 39/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.7110 - acc: 0.3272 - val_loss: 3.2400 - val_acc: 0.2431\n","Epoch 40/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.7777 - acc: 0.3166 - val_loss: 3.5287 - val_acc: 0.2210\n","Epoch 41/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.8493 - acc: 0.3025 - val_loss: 3.4386 - val_acc: 0.2245\n","Epoch 42/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 2.9541 - acc: 0.2836 - val_loss: 3.4503 - val_acc: 0.2133\n","Epoch 43/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 3.0524 - acc: 0.2654 - val_loss: 3.4479 - val_acc: 0.2151\n","Epoch 44/50\n","50000/50000 [==============================] - 159s 3ms/step - loss: 3.2105 - acc: 0.2373 - val_loss: 3.5842 - val_acc: 0.1740\n","Epoch 45/50\n","50000/50000 [==============================] - 158s 3ms/step - loss: 3.2913 - acc: 0.2219 - val_loss: 3.9931 - val_acc: 0.1142\n","Epoch 46/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.4997 - acc: 0.1852 - val_loss: 3.9216 - val_acc: 0.1348\n","Epoch 47/50\n","50000/50000 [==============================] - 156s 3ms/step - loss: 3.7880 - acc: 0.1349 - val_loss: 4.1480 - val_acc: 0.0825\n","Epoch 48/50\n","50000/50000 [==============================] - 155s 3ms/step - loss: 8.5019 - acc: 0.0718 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 49/50\n","50000/50000 [==============================] - 154s 3ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 50/50\n","50000/50000 [==============================] - 152s 3ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Batch Size: 64\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_8 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 97s 2ms/step - loss: 5.0588 - acc: 0.0093 - val_loss: 4.8668 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7707 - acc: 0.0099 - val_loss: 4.7700 - val_acc: 0.0100\n","Epoch 3/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7581 - acc: 0.0098 - val_loss: 4.7724 - val_acc: 0.0100\n","Epoch 4/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7500 - acc: 0.0100 - val_loss: 4.7723 - val_acc: 0.0100\n","Epoch 5/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7466 - acc: 0.0103 - val_loss: 4.7548 - val_acc: 0.0100\n","Epoch 6/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7440 - acc: 0.0093 - val_loss: 4.7443 - val_acc: 0.0100\n","Epoch 7/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7410 - acc: 0.0100 - val_loss: 4.7515 - val_acc: 0.0100\n","Epoch 8/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7398 - acc: 0.0095 - val_loss: 4.7461 - val_acc: 0.0100\n","Epoch 9/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7372 - acc: 0.0097 - val_loss: 4.7394 - val_acc: 0.0100\n","Epoch 10/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7354 - acc: 0.0104 - val_loss: 4.7375 - val_acc: 0.0100\n","Epoch 11/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.7022 - acc: 0.0143 - val_loss: 4.7421 - val_acc: 0.0100\n","Epoch 12/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.5668 - acc: 0.0238 - val_loss: 4.4612 - val_acc: 0.0304\n","Epoch 13/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.3104 - acc: 0.0437 - val_loss: 4.4360 - val_acc: 0.0449\n","Epoch 14/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.1447 - acc: 0.0636 - val_loss: 4.2486 - val_acc: 0.0467\n","Epoch 15/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 4.0228 - acc: 0.0843 - val_loss: 4.1717 - val_acc: 0.0701\n","Epoch 16/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.8745 - acc: 0.1070 - val_loss: 5.1543 - val_acc: 0.0723\n","Epoch 17/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.7395 - acc: 0.1313 - val_loss: 4.0911 - val_acc: 0.0975\n","Epoch 18/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.5756 - acc: 0.1619 - val_loss: 3.9461 - val_acc: 0.1378\n","Epoch 19/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.4086 - acc: 0.1930 - val_loss: 3.6593 - val_acc: 0.1694\n","Epoch 20/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.2541 - acc: 0.2226 - val_loss: 4.0405 - val_acc: 0.1380\n","Epoch 21/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 3.0984 - acc: 0.2512 - val_loss: 3.4784 - val_acc: 0.2096\n","Epoch 22/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.9442 - acc: 0.2819 - val_loss: 3.5268 - val_acc: 0.2022\n","Epoch 23/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.7986 - acc: 0.3120 - val_loss: 3.3457 - val_acc: 0.2225\n","Epoch 24/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.6564 - acc: 0.3413 - val_loss: 3.4272 - val_acc: 0.2322\n","Epoch 25/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.5339 - acc: 0.3685 - val_loss: 3.4460 - val_acc: 0.2308\n","Epoch 26/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.4328 - acc: 0.3899 - val_loss: 3.3233 - val_acc: 0.2680\n","Epoch 27/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.3136 - acc: 0.4134 - val_loss: 3.2614 - val_acc: 0.2622\n","Epoch 28/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.2293 - acc: 0.4333 - val_loss: 3.5933 - val_acc: 0.2557\n","Epoch 29/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.1748 - acc: 0.4515 - val_loss: 3.4290 - val_acc: 0.2610\n","Epoch 30/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.0805 - acc: 0.4717 - val_loss: 3.7853 - val_acc: 0.2409\n","Epoch 31/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 2.0100 - acc: 0.4885 - val_loss: 3.7450 - val_acc: 0.2449\n","Epoch 32/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.9803 - acc: 0.4983 - val_loss: 3.6747 - val_acc: 0.2768\n","Epoch 33/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.9180 - acc: 0.5117 - val_loss: 3.4252 - val_acc: 0.2908\n","Epoch 34/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.8757 - acc: 0.5244 - val_loss: 3.4880 - val_acc: 0.2857\n","Epoch 35/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.8742 - acc: 0.5261 - val_loss: 3.7871 - val_acc: 0.2452\n","Epoch 36/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.8452 - acc: 0.5227 - val_loss: 4.4951 - val_acc: 0.2225\n","Epoch 37/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.7540 - acc: 0.5397 - val_loss: 3.6567 - val_acc: 0.2690\n","Epoch 38/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.7013 - acc: 0.5508 - val_loss: 3.5214 - val_acc: 0.2936\n","Epoch 39/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6944 - acc: 0.5532 - val_loss: 4.1368 - val_acc: 0.2367\n","Epoch 40/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6780 - acc: 0.5561 - val_loss: 3.4258 - val_acc: 0.2808\n","Epoch 41/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6608 - acc: 0.5625 - val_loss: 3.5836 - val_acc: 0.2918\n","Epoch 42/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6588 - acc: 0.5639 - val_loss: 3.4256 - val_acc: 0.2911\n","Epoch 43/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6457 - acc: 0.5700 - val_loss: 3.5270 - val_acc: 0.2972\n","Epoch 44/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.6657 - acc: 0.5666 - val_loss: 3.8469 - val_acc: 0.2549\n","Epoch 45/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.7885 - acc: 0.5431 - val_loss: 3.6717 - val_acc: 0.2824\n","Epoch 46/50\n","50000/50000 [==============================] - 94s 2ms/step - loss: 1.7858 - acc: 0.5438 - val_loss: 3.7157 - val_acc: 0.2774\n","Epoch 47/50\n","50000/50000 [==============================] - 93s 2ms/step - loss: 1.8693 - acc: 0.5288 - val_loss: 3.6189 - val_acc: 0.2606\n","Epoch 48/50\n","50000/50000 [==============================] - 93s 2ms/step - loss: 1.9551 - acc: 0.5113 - val_loss: 3.6140 - val_acc: 0.2660\n","Epoch 49/50\n","50000/50000 [==============================] - 93s 2ms/step - loss: 2.0087 - acc: 0.4997 - val_loss: 3.7400 - val_acc: 0.2447\n","Epoch 50/50\n","50000/50000 [==============================] - 93s 2ms/step - loss: 2.1305 - acc: 0.4743 - val_loss: 3.4295 - val_acc: 0.2871\n","Batch Size: 96\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_9 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 86s 2ms/step - loss: 5.1543 - acc: 0.0094 - val_loss: 4.7767 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7726 - acc: 0.0099 - val_loss: 4.7682 - val_acc: 0.0100\n","Epoch 3/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 4.7593 - acc: 0.0099 - val_loss: 4.7495 - val_acc: 0.0100\n","Epoch 4/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7525 - acc: 0.0099 - val_loss: 4.7546 - val_acc: 0.0100\n","Epoch 5/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7480 - acc: 0.0094 - val_loss: 4.7467 - val_acc: 0.0100\n","Epoch 6/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7448 - acc: 0.0094 - val_loss: 4.7384 - val_acc: 0.0100\n","Epoch 7/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7408 - acc: 0.0096 - val_loss: 4.7353 - val_acc: 0.0100\n","Epoch 8/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7386 - acc: 0.0104 - val_loss: 4.7380 - val_acc: 0.0100\n","Epoch 9/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7376 - acc: 0.0105 - val_loss: 4.7377 - val_acc: 0.0100\n","Epoch 10/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7362 - acc: 0.0107 - val_loss: 4.7373 - val_acc: 0.0100\n","Epoch 11/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7350 - acc: 0.0099 - val_loss: 4.7309 - val_acc: 0.0100\n","Epoch 12/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 4.7341 - acc: 0.0097 - val_loss: 4.7323 - val_acc: 0.0100\n","Epoch 13/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 4.7328 - acc: 0.0092 - val_loss: 4.7337 - val_acc: 0.0100\n","Epoch 14/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7275 - acc: 0.0106 - val_loss: 4.7286 - val_acc: 0.0121\n","Epoch 15/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.6924 - acc: 0.0135 - val_loss: 4.7301 - val_acc: 0.0100\n","Epoch 16/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.7149 - acc: 0.0122 - val_loss: 4.7715 - val_acc: 0.0101\n","Epoch 17/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 4.5731 - acc: 0.0198 - val_loss: 4.4861 - val_acc: 0.0261\n","Epoch 18/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.4201 - acc: 0.0280 - val_loss: 4.3884 - val_acc: 0.0318\n","Epoch 19/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.3421 - acc: 0.0382 - val_loss: 4.2568 - val_acc: 0.0468\n","Epoch 20/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.2472 - acc: 0.0497 - val_loss: 4.2160 - val_acc: 0.0495\n","Epoch 21/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 4.1442 - acc: 0.0612 - val_loss: 4.1106 - val_acc: 0.0694\n","Epoch 22/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 4.0398 - acc: 0.0784 - val_loss: 3.9788 - val_acc: 0.0875\n","Epoch 23/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 3.8867 - acc: 0.1038 - val_loss: 3.8377 - val_acc: 0.1202\n","Epoch 24/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 3.6740 - acc: 0.1340 - val_loss: 3.5492 - val_acc: 0.1521\n","Epoch 25/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 3.4397 - acc: 0.1673 - val_loss: 3.4008 - val_acc: 0.1818\n","Epoch 26/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 3.2264 - acc: 0.2066 - val_loss: 3.3394 - val_acc: 0.1888\n","Epoch 27/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 3.0232 - acc: 0.2444 - val_loss: 3.0195 - val_acc: 0.2534\n","Epoch 28/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 2.8204 - acc: 0.2834 - val_loss: 2.9937 - val_acc: 0.2653\n","Epoch 29/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 2.6261 - acc: 0.3180 - val_loss: 3.2529 - val_acc: 0.2332\n","Epoch 30/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 2.4421 - acc: 0.3583 - val_loss: 2.8339 - val_acc: 0.3005\n","Epoch 31/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 2.2793 - acc: 0.3944 - val_loss: 3.0560 - val_acc: 0.2880\n","Epoch 32/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 2.1129 - acc: 0.4302 - val_loss: 2.8498 - val_acc: 0.3152\n","Epoch 33/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.9696 - acc: 0.4638 - val_loss: 2.7440 - val_acc: 0.3459\n","Epoch 34/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 1.8331 - acc: 0.4962 - val_loss: 2.9009 - val_acc: 0.3247\n","Epoch 35/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 1.6984 - acc: 0.5249 - val_loss: 2.7404 - val_acc: 0.3557\n","Epoch 36/50\n","50000/50000 [==============================] - 82s 2ms/step - loss: 1.5773 - acc: 0.5549 - val_loss: 2.9532 - val_acc: 0.3400\n","Epoch 37/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.4497 - acc: 0.5856 - val_loss: 2.8423 - val_acc: 0.3562\n","Epoch 38/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.3688 - acc: 0.6074 - val_loss: 2.9775 - val_acc: 0.3375\n","Epoch 39/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.2753 - acc: 0.6319 - val_loss: 3.0386 - val_acc: 0.3517\n","Epoch 40/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.1999 - acc: 0.6519 - val_loss: 3.1251 - val_acc: 0.3436\n","Epoch 41/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.1134 - acc: 0.6765 - val_loss: 2.9252 - val_acc: 0.3679\n","Epoch 42/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 1.0668 - acc: 0.6872 - val_loss: 3.3677 - val_acc: 0.3512\n","Epoch 43/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.9852 - acc: 0.7091 - val_loss: 3.0597 - val_acc: 0.3561\n","Epoch 44/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.9599 - acc: 0.7213 - val_loss: 3.2387 - val_acc: 0.3640\n","Epoch 45/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.9139 - acc: 0.7341 - val_loss: 3.2695 - val_acc: 0.3636\n","Epoch 46/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.8813 - acc: 0.7443 - val_loss: 3.1276 - val_acc: 0.3590\n","Epoch 47/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.8474 - acc: 0.7546 - val_loss: 3.4036 - val_acc: 0.3620\n","Epoch 48/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.8243 - acc: 0.7635 - val_loss: 3.4839 - val_acc: 0.3596\n","Epoch 49/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.8011 - acc: 0.7712 - val_loss: 3.2266 - val_acc: 0.3620\n","Epoch 50/50\n","50000/50000 [==============================] - 81s 2ms/step - loss: 0.7669 - acc: 0.7804 - val_loss: 3.5236 - val_acc: 0.3591\n","Batch Size: 128\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_10 (InputLayer)        (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 72s 1ms/step - loss: 15.5871 - acc: 0.0096 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 3/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 4/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 5/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 6/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 7/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 8/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 9/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 10/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 11/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 12/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 13/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 14/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 15/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 16/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 17/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 18/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 19/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 20/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 21/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 22/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 23/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 24/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 25/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 26/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 27/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 28/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 29/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 30/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 31/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 32/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 33/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 34/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 35/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 36/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 37/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 38/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 39/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 40/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 41/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 42/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 43/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 44/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 45/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 46/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 47/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 48/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 49/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Epoch 50/50\n","50000/50000 [==============================] - 69s 1ms/step - loss: 15.9570 - acc: 0.0100 - val_loss: 15.9570 - val_acc: 0.0100\n","Batch Size: 160\n","Learning Rate: 0.075\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_11 (InputLayer)        (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              2101248   \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 43,003,944\n","Trainable params: 43,003,944\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 72s 1ms/step - loss: 5.6065 - acc: 0.0093 - val_loss: 4.9332 - val_acc: 0.0100\n","Epoch 2/50\n","50000/50000 [==============================] - 67s 1ms/step - loss: 4.8762 - acc: 0.0097 - val_loss: 4.8972 - val_acc: 0.0100\n","Epoch 3/50\n","47360/50000 [===========================>..] - ETA: 3s - loss: 4.8606 - acc: 0.0098"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jzmsNKtwzrhv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}