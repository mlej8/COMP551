{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WilliamYkZhang/COMP551_A2/blob/master/model_selection_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwvRwn8uRfqH"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "# Transformers \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Module to write final params \n",
    "import csv\n",
    "import datetime\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Dxz1MZOMR6TA",
    "outputId": "0da16cf3-7c1a-4583-f07c-283caac8b10d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mlej\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWP9xvmNRpgF"
   },
   "outputs": [],
   "source": [
    "def grid_search_cv(model, X, y, params, folds):\n",
    "    # Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(smooth_idf=True, norm='l2', lowercase=True, max_features=30000, use_idf=True, encoding = \"utf-8\",  decode_error = 'ignore', strip_accents='unicode', stop_words=stopwords.words('english'), analyzer = \"word\")),\n",
    "        ('clf', model)],\n",
    "         verbose=True)\n",
    "\n",
    "    # Use GridSearch cross validation to find the best feature extraction and hyperparameters\n",
    "    gs_CV = GridSearchCV(pipeline, param_grid=params, cv=folds)\n",
    "    gs_CV.fit(X, y)\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline: \", [name for name, _ in pipeline.steps])\n",
    "    print(\"Best parameter (CV score={0:.3f}):\".format(gs_CV.best_score_))\n",
    "    print(\"Best parameters set: {} \\nBest estimator parameters {}.\".format(gs_CV.best_params_, gs_CV.best_estimator_.get_params()))\n",
    "\n",
    "    return (gs_CV.best_score_,gs_CV.best_params_, gs_CV.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AnWS8Y7TTSL"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'XGBClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-db9a0be482e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Instantiate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'XGBClassifier'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "parameters_tfidf = {\n",
    "'clf__booster': ('gbtree', 'gblinear'),\n",
    "'clf__objective':('multi:softmax', 'binary:logistic'),   \n",
    "# 'clf__eval_metric':('rmse', 'mae', 'logloss', 'logloss', 'error', 'merror', 'mlogloss', 'auc'),\n",
    "# 'clf__seed': (0,1,2,3),\n",
    "'clf__eta': (0.3,0.5), # learning rate\n",
    "'clf__min_child_weight':(1,3,5,10), # Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "'clf__max_depth': (3,6,9),\n",
    "}  \n",
    "\n",
    "# Instantiate model\n",
    "clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBcky3XeR2wD"
   },
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "stemmed_df = pd.read_csv(\"https://raw.githubusercontent.com/WilliamYkZhang/COMP551_A2/master/preprocessed_reddit_train_SnowballStemmer.csv?token=AKKZG4GENVP2WXEXXHZVHSS5WRRRY\")\n",
    "\n",
    "# Separate X and Y \n",
    "X_stem = stemmed_df[\"cleaned\"]\n",
    "y_stem = stemmed_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ncqur8JUSDNE",
    "outputId": "85499f05-119c-4463-ed04-4da879424719"
   },
   "outputs": [],
   "source": [
    "best_scores, best_params, best_estimator_params = grid_search_cv(model=clf, X=X_stem, y=y_stem,params=parameters_tfidf,folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "model_selection_xgboost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
